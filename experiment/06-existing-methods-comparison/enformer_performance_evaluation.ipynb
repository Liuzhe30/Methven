{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction performance of Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, accuracy_score,recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '../../model/pred_results_tenfold_enformer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+------+\n",
      "|  ACC  | Precision | Recall | F1-score | AUC  |\n",
      "+-------+-----------+--------+----------+------+\n",
      "| 0.895 |   0.914   | 0.878  |  0.896   | 0.96 |\n",
      "+-------+-----------+--------+----------+------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.901 |   0.919   | 0.886  |  0.902   | 0.963 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.884 |   0.893   | 0.873  |  0.883   | 0.951 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.895 |   0.908   | 0.878  |  0.893   | 0.964 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+------+\n",
      "|  ACC  | Precision | Recall | F1-score | AUC  |\n",
      "+-------+-----------+--------+----------+------+\n",
      "| 0.889 |   0.917   | 0.859  |  0.887   | 0.96 |\n",
      "+-------+-----------+--------+----------+------+\n",
      "+-------+-----------+--------+----------+------+\n",
      "|  ACC  | Precision | Recall | F1-score | AUC  |\n",
      "+-------+-----------+--------+----------+------+\n",
      "| 0.894 |   0.902   | 0.878  |   0.89   | 0.96 |\n",
      "+-------+-----------+--------+----------+------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.902 |   0.914   |  0.89  |  0.902   | 0.959 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.891 |   0.895   | 0.883  |  0.889   | 0.959 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.899 |   0.908   | 0.881  |  0.895   | 0.959 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.888 |   0.907   | 0.866  |  0.886   | 0.952 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "(mean) ACC:  0.8938 Precision:  0.9077 Recall:  0.8772 F1:  0.8922999999999999 AUC:  0.9587\n",
      "(std) ACC:  0.005564171097297428 Precision:  0.008391066678319278 Recall:  0.008749857141690952 F1:  0.006165225056719346 AUC:  0.003950949253027686\n"
     ]
    }
   ],
   "source": [
    "model_size = 'small'\n",
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "for f in range(10):\n",
    "    fold = str(f+1)\n",
    "    label = np.load(result_path + model_size + '_split' + fold + '_label.npy')\n",
    "    y_score = np.load(result_path + model_size +'_split' + fold + '_score.npy')\n",
    "    y_score_pro = np.load(result_path + model_size + '_split' + fold + '_score_pro.npy')\n",
    "    y_one_hot = to_categorical(label)\n",
    "    y_score_one_hot = to_categorical(y_score)\n",
    "\n",
    "    acc = np.round(accuracy_score(label, y_score),3)\n",
    "    precision = np.round(precision_score(label, y_score),3)\n",
    "    recall = np.round(recall_score(label, y_score),3)\n",
    "    f1 = np.round(f1_score(label, y_score),3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_one_hot.ravel(),y_score_pro.ravel()) \n",
    "    auc_ = np.round(auc(fpr, tpr),3)\n",
    "\n",
    "    table = PrettyTable(['ACC','Precision','Recall','F1-score','AUC'])\n",
    "    table.add_row([acc,precision,recall,f1,auc_])\n",
    "    print(table)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    auc_list.append(auc_)\n",
    "\n",
    "print('(mean) ACC: ', np.mean(acc_list), 'Precision: ', np.mean(precision_list), 'Recall: ', np.mean(recall_list), 'F1: ', np.mean(f1_list), 'AUC: ', np.mean(auc_list))\n",
    "print('(std) ACC: ', np.std(acc_list), 'Precision: ', np.std(precision_list), 'Recall: ', np.std(recall_list), 'F1: ', np.std(f1_list), 'AUC: ', np.std(auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.829 |   0.849   | 0.807  |  0.828   | 0.911 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.823 |   0.838   | 0.815  |  0.826   | 0.911 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.837 |   0.829   |  0.83  |  0.829   | 0.913 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.834 |   0.845   | 0.816  |   0.83   | 0.918 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.824 |   0.842   | 0.808  |  0.825   | 0.915 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.823 |   0.839   | 0.793  |  0.815   | 0.906 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.838 |   0.854   | 0.814  |  0.834   | 0.914 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.816 |   0.828   | 0.791  |  0.809   | 0.904 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+------+\n",
      "|  ACC  | Precision | Recall | F1-score | AUC  |\n",
      "+-------+-----------+--------+----------+------+\n",
      "| 0.835 |   0.847   | 0.823  |  0.835   | 0.92 |\n",
      "+-------+-----------+--------+----------+------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.833 |    0.85   | 0.815  |  0.832   | 0.916 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "(mean) ACC:  0.8291999999999998 Precision:  0.8421 Recall:  0.8112 F1:  0.8263 AUC:  0.9128000000000001\n",
      "(std) ACC:  0.006982836100038443 Precision:  0.008251666498350506 Recall:  0.01148738438461947 F1:  0.007874642849043994 AUC:  0.004749736834815171\n"
     ]
    }
   ],
   "source": [
    "model_size = 'large'\n",
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "for f in range(10):\n",
    "    fold = str(f+1)\n",
    "    label = np.load(result_path + model_size + '_split' + fold + '_label.npy')\n",
    "    y_score = np.load(result_path + model_size +'_split' + fold + '_score.npy')\n",
    "    y_score_pro = np.load(result_path + model_size + '_split' + fold + '_score_pro.npy')\n",
    "    y_one_hot = to_categorical(label)\n",
    "    y_score_one_hot = to_categorical(y_score)\n",
    "\n",
    "    acc = np.round(accuracy_score(label, y_score),3)\n",
    "    precision = np.round(precision_score(label, y_score),3)\n",
    "    recall = np.round(recall_score(label, y_score),3)\n",
    "    f1 = np.round(f1_score(label, y_score),3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_one_hot.ravel(),y_score_pro.ravel()) \n",
    "    auc_ = np.round(auc(fpr, tpr),3)\n",
    "\n",
    "    table = PrettyTable(['ACC','Precision','Recall','F1-score','AUC'])\n",
    "    table.add_row([acc,precision,recall,f1,auc_])\n",
    "    print(table)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    auc_list.append(auc_)\n",
    "\n",
    "print('(mean) ACC: ', np.mean(acc_list), 'Precision: ', np.mean(precision_list), 'Recall: ', np.mean(recall_list), 'F1: ', np.mean(f1_list), 'AUC: ', np.mean(auc_list))\n",
    "print('(std) ACC: ', np.std(acc_list), 'Precision: ', np.std(precision_list), 'Recall: ', np.std(recall_list), 'F1: ', np.std(f1_list), 'AUC: ', np.std(auc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fff98fc3b3d81bd655c2cc48858186e4d9e2db7b515bf1c3221888f12a62f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

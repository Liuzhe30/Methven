{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction performance of Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, accuracy_score,recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'pred_results_tenfold_enformer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.825 |    0.84   | 0.813  |  0.826   | 0.825 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.811 |   0.819   | 0.812  |  0.815   | 0.811 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.823 |   0.821   | 0.829  |  0.825   | 0.823 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.809 |   0.805   | 0.812  |  0.808   | 0.809 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.824 |   0.844   | 0.803  |  0.823   | 0.824 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.824 |   0.808   | 0.837  |  0.822   | 0.824 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.812 |   0.809   |  0.82  |  0.815   | 0.812 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.789 |   0.785   | 0.787  |  0.786   | 0.789 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.817 |   0.815   |  0.81  |  0.812   | 0.817 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.793 |   0.795   | 0.792  |  0.793   | 0.793 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "(mean) ACC:  0.8126999999999999 Precision:  0.8141 Recall:  0.8115 F1:  0.8125 AUC:  0.8126999999999999\n",
      "(std) ACC:  0.012239689538546277 Precision:  0.01730577938146673 Recall:  0.014444722219551306 F1:  0.012862736878285243 AUC:  0.012239689538546277\n"
     ]
    }
   ],
   "source": [
    "model_size = 'small'\n",
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "for f in range(10):\n",
    "    fold = str(f+1)\n",
    "    label = np.load(result_path + model_size + '_split' + fold + '_label.npy')\n",
    "    y_score = np.load(result_path + model_size +'_split' + fold + '_score.npy')\n",
    "    y_score_pro = np.load(result_path + model_size + '_split' + fold + '_score_pro.npy')\n",
    "    y_one_hot = to_categorical(label)\n",
    "    y_score_one_hot = to_categorical(y_score)\n",
    "\n",
    "    acc = np.round(accuracy_score(label, y_score),3)\n",
    "    precision = np.round(precision_score(label, y_score),3)\n",
    "    recall = np.round(recall_score(label, y_score),3)\n",
    "    f1 = np.round(f1_score(label, y_score),3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_one_hot.ravel(),y_score_pro.ravel()) \n",
    "    auc_ = np.round(auc(fpr, tpr),3)\n",
    "\n",
    "    table = PrettyTable(['ACC','Precision','Recall','F1-score','AUC'])\n",
    "    table.add_row([acc,precision,recall,f1,auc_])\n",
    "    print(table)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    auc_list.append(auc_)\n",
    "\n",
    "print('(mean) ACC: ', np.mean(acc_list), 'Precision: ', np.mean(precision_list), 'Recall: ', np.mean(recall_list), 'F1: ', np.mean(f1_list), 'AUC: ', np.mean(auc_list))\n",
    "print('(std) ACC: ', np.std(acc_list), 'Precision: ', np.std(precision_list), 'Recall: ', np.std(recall_list), 'F1: ', np.std(f1_list), 'AUC: ', np.std(auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.759 |   0.764   |  0.76  |  0.762   | 0.759 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.753 |   0.763   | 0.757  |   0.76   | 0.753 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.742 |   0.716   | 0.763  |  0.739   | 0.742 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.775 |   0.762   | 0.797  |  0.779   | 0.775 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.752 |   0.758   | 0.758  |  0.758   | 0.752 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.759 |   0.755   | 0.757  |  0.756   | 0.759 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+------+\n",
      "|  ACC  | Precision | Recall | F1-score | AUC  |\n",
      "+-------+-----------+--------+----------+------+\n",
      "| 0.759 |   0.767   | 0.746  |  0.756   | 0.76 |\n",
      "+-------+-----------+--------+----------+------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.752 |   0.748   | 0.747  |  0.748   | 0.752 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.744 |   0.743   | 0.755  |  0.749   | 0.744 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "+-------+-----------+--------+----------+-------+\n",
      "|  ACC  | Precision | Recall | F1-score |  AUC  |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "| 0.759 |   0.768   | 0.753  |  0.761   | 0.759 |\n",
      "+-------+-----------+--------+----------+-------+\n",
      "(mean) ACC:  0.7554000000000001 Precision:  0.7544 Recall:  0.7593 F1:  0.7567999999999999 AUC:  0.7555\n",
      "(std) ACC:  0.008800000000000007 Precision:  0.0149211259628756 Recall:  0.013542894816101922 F1:  0.010027960909377348 AUC:  0.008845903006477075\n"
     ]
    }
   ],
   "source": [
    "model_size = 'large'\n",
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "for f in range(10):\n",
    "    fold = str(f+1)\n",
    "    label = np.load(result_path + model_size + '_split' + fold + '_label.npy')\n",
    "    y_score = np.load(result_path + model_size +'_split' + fold + '_score.npy')\n",
    "    y_score_pro = np.load(result_path + model_size + '_split' + fold + '_score_pro.npy')\n",
    "    y_one_hot = to_categorical(label)\n",
    "    y_score_one_hot = to_categorical(y_score)\n",
    "\n",
    "    acc = np.round(accuracy_score(label, y_score),3)\n",
    "    precision = np.round(precision_score(label, y_score),3)\n",
    "    recall = np.round(recall_score(label, y_score),3)\n",
    "    f1 = np.round(f1_score(label, y_score),3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_one_hot.ravel(),y_score_pro.ravel()) \n",
    "    auc_ = np.round(auc(fpr, tpr),3)\n",
    "\n",
    "    table = PrettyTable(['ACC','Precision','Recall','F1-score','AUC'])\n",
    "    table.add_row([acc,precision,recall,f1,auc_])\n",
    "    print(table)\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    auc_list.append(auc_)\n",
    "\n",
    "print('(mean) ACC: ', np.mean(acc_list), 'Precision: ', np.mean(precision_list), 'Recall: ', np.mean(recall_list), 'F1: ', np.mean(f1_list), 'AUC: ', np.mean(auc_list))\n",
    "print('(std) ACC: ', np.std(acc_list), 'Precision: ', np.std(precision_list), 'Recall: ', np.std(recall_list), 'F1: ', np.std(f1_list), 'AUC: ', np.std(auc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fff98fc3b3d81bd655c2cc48858186e4d9e2db7b515bf1c3221888f12a62f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
